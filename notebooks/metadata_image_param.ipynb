{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this proof of concept we will read & write JSON files in Jupyter notebook. \n",
    "\n",
    "1. display the data in the sidecar \n",
    "2. edit this data \n",
    "3. check that the sidecar will write valid JSON files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json module to be able to read & write json files \n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from glob import glob \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The first part will include displaying the data in the sidecar by reading the JSON files \n",
    "2. We then use json.load to turn it into a python object \n",
    "3. The data we have includes an array of information under SliceTiming so we will create a dataframe within our dataframe to include SliceTiming as SliceTime 00, 01 , etc. (individual values of SliceTiming). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ProcedureStepDescription</th>\n",
       "      <td>MR_HEAD_WO_IV_CONTRAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeviceSerialNumber</th>\n",
       "      <td>167024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EffectiveEchoSpacing</th>\n",
       "      <td>0.000689998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalReadoutTime</th>\n",
       "      <td>0.0717598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ManufacturersModelName</th>\n",
       "      <td>Prisma_fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SliceTime031</th>\n",
       "      <td>3.61667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SliceTime032</th>\n",
       "      <td>3.73333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SliceTime033</th>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SliceTime034</th>\n",
       "      <td>3.96667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SliceTime035</th>\n",
       "      <td>4.08333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               1\n",
       "ProcedureStepDescription  MR_HEAD_WO_IV_CONTRAST\n",
       "DeviceSerialNumber                        167024\n",
       "EffectiveEchoSpacing                 0.000689998\n",
       "TotalReadoutTime                       0.0717598\n",
       "ManufacturersModelName                Prisma_fit\n",
       "...                                          ...\n",
       "SliceTime031                             3.61667\n",
       "SliceTime032                             3.73333\n",
       "SliceTime033                                3.85\n",
       "SliceTime034                             3.96667\n",
       "SliceTime035                             4.08333\n",
       "\n",
       "[64 rows x 1 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing the code with a single json file. \n",
    "\n",
    "file_test = open('/Users/bjaber/Projects/CuBIDS-use_cases/cubids/testdata/complete/sub-01/ses-phdiff/dwi/sub-01_ses-phdiff_acq-HASC55AP_dwi.json')\n",
    "sample_data = json.load(file_test)\n",
    "sample_data.keys()\n",
    "sample_data.get('SliceTiming')\n",
    "SliceTime = sample_data.get('SliceTiming') #the way you can snatch things out of a dictionary \n",
    "#if dict doesn't have the key it will return none vs. error\n",
    "\n",
    "if SliceTime: \n",
    "    sample_data.update({\"SliceTime%03d\"%SliceNum : time for SliceNum, time in enumerate(SliceTime)})\n",
    "    del sample_data['SliceTiming']\n",
    "    \n",
    "array_data = pd.DataFrame.from_dict(sample_data, orient='index', columns = ['1'])\n",
    "array_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{\"SliceTime%03d\"%SliceNum : time for SliceNum, time in enumerate(SliceTime)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the next one might not have slice timing but you concatenate the next row -- if the file doesn't have slice timing it fills with NaN and if it doesn't then google! \n",
    "\n",
    "rglob to get all the files in the bids tree then load it with json.load "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps \n",
    "\n",
    "1. Slice Timing turn it into a column where each column would have its own float \n",
    "2. multiple columns with the umber of them filled out to the maximum number of slice times "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The following part is used to edit JSON file data. \n",
    "\n",
    "In order to do so, call to the JSON object that was created using the json.load commeand, in this case json_data, and refer to the value that you want to change and edit it. \n",
    "\n",
    "Note that this code is commented out as it will be different when we are using this with Pandas DataFrame. This was code written when working with a single .json file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we change the value for AcquisionNumber from 1 to 2. \n",
    "#json_data[\"AcquisitionNumber\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment below to view edited data\n",
    "#json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverting back to original data\n",
    "#json_data[\"AcquisitionNumber\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Checking that the sidecare will write valid JSON files \n",
    "\n",
    "In order to do this, we use the json.dumps function as it will turn the python object into a JSON string, and therefore, will write a valid JSON file always. \n",
    "\n",
    "Note: same as the previous chunk of code, this was written for a single .json file and therefore is commentend out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_string = json.dumps(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment below to view the python object as a JSON string \n",
    "#json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes from Matt \n",
    "\n",
    "# have a function that does the reading and creates 1 row then you have to loop and the dataframe grows through concatanation \n",
    "# pandas.concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section is the for loop attempting to extract, open and turn into a dataframe each json file in the \"complete\" directory! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n",
      "<class 'pathlib.PosixPath'>\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EchoTime</th>\n",
       "      <th>EffectiveEchoSpacing</th>\n",
       "      <th>TotalReadoutTime</th>\n",
       "      <th>FlipAngle</th>\n",
       "      <th>RepetitionTime</th>\n",
       "      <th>PhaseEncodingDirection</th>\n",
       "      <th>PartialFourier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.08900</td>\n",
       "      <td>0.00069</td>\n",
       "      <td>0.07176</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>j</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>j-</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>j-</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08900</td>\n",
       "      <td>0.00069</td>\n",
       "      <td>0.07176</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>j-</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EchoTime  EffectiveEchoSpacing  TotalReadoutTime  FlipAngle  \\\n",
       "0       NaN                   NaN               NaN        NaN   \n",
       "1   0.08900               0.00069           0.07176       90.0   \n",
       "2       NaN                   NaN               NaN       60.0   \n",
       "3   0.00646                   NaN               NaN       60.0   \n",
       "4   0.08900               0.00069           0.07176       90.0   \n",
       "\n",
       "   RepetitionTime PhaseEncodingDirection  PartialFourier  \n",
       "0             NaN                    NaN             NaN  \n",
       "1             4.2                      j             NaN  \n",
       "2             1.5                     j-            0.75  \n",
       "3             1.5                     j-            0.75  \n",
       "4             4.2                     j-             NaN  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGING_PARAMS = set([\"ParallelReductionFactorInPlane\", \"ParallelAcquisitionTechnique\",\n",
    "    \"ParallelAcquisitionTechnique\", \"PartialFourier\", \"PhaseEncodingDirection\",\n",
    "    \"EffectiveEchoSpacing\", \"TotalReadoutTime\", \"EchoTime\", \"SliceEncodingDirection\",\n",
    "    \"DwellTime\", \"FlipAngle\", \"MultibandAccelerationFactor\", \"RepetitionTime\",\n",
    "    \"VolumeTiming\", \"NumberOfVolumesDiscardedByScanner\", \"NumberOfVolumesDiscardedByUser\"])\n",
    "\n",
    "dfs = [] # an empty list to store the data frames\n",
    "\n",
    "counter=0\n",
    "\n",
    "for path in Path('/Users/bjaber/Projects/CuBIDS/cubids/testdata/complete').rglob('*.json'):\n",
    "    print(type(path))\n",
    "    print(counter)\n",
    "    s_path = str(path)\n",
    "    #print(s_path)\n",
    "    file_tree = open(s_path)\n",
    "    example_data = json.load(file_tree)\n",
    "    wanted_keys = example_data.keys() & IMAGING_PARAMS\n",
    "    example_data = {key: example_data[key] for key in wanted_keys} \n",
    "    SliceTime = example_data.get('SliceTiming') #the way you can snatch things out of a dictionary #if dict doesn't have the key it will return none vs. error\n",
    "    if SliceTime: \n",
    "        example_data.update({\"SliceTime%03d\"%SliceNum : [time] for SliceNum, time in enumerate(SliceTime)})\n",
    "        del example_data['SliceTiming']\n",
    "    #if ShimSetting:\n",
    "        \n",
    "    dfs.append(example_data)\n",
    "    \n",
    "df = pd.DataFrame(dfs)\n",
    "#df.drop_duplicates()\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "#create dataframe of unique rows \n",
    "#bids entities filter in the cubids class to filter through the files \n",
    "#loop over , get metadata, and put into the dataframe \n",
    "\n",
    "\n",
    "\n",
    "        #print(example_data)\n",
    "\n",
    "\n",
    "    \n",
    "#for file in example_data:\n",
    "    #data = pd.DataFrame.from_dict(example_data, orient='index') # read data frame from json file\n",
    "    #dfs.append(data) # append the data frame to the list\n",
    "    #temp = pd.concat(dfs, ignore_index=True) # concatenate all the data frames in the list.\n",
    "\n",
    "    #data = pd.DataFrame.from_dict(example_data, orient='index') \n",
    "    #data\n",
    "    #counter += 1\n",
    "    \n",
    "\n",
    "#NOTE: error when trying to put the data into a pandas dataframe. This error happens regardless of the way SliceTiming is setup. \n",
    "# print(example_data) was used to make sure that inputs that are an array such as in the field SliceTiming are being separated into indenpendent values of SliceTime00x that should feed into the dataframe. \n",
    "# it is doing that across all json files that are being loaded from the directory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just documented attempts at the above for loop! \n",
    "\n",
    "attempt at directory stuff #1 \n",
    "\n",
    "import os, json\n",
    "import pandas as pd\n",
    "\n",
    "path_to_json = '/Users/bjaber/Projects/CuBIDS-use_cases/cubids/testdata/complete/sub-01/ses-phdiff/anat'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "print(json_files)\n",
    "\n",
    "attempt #2\n",
    "\n",
    "for filename in glob('/Users/bjaber/Projects/CuBIDS-use_cases/cubids/testdata/complete/*.json'):\n",
    "    print(filename)\n",
    "    \n",
    "    \n",
    "attempt # 3    \n",
    "    \n",
    " for name in files: \n",
    "    f = open(name, 'r')\n",
    "    print(f)\n",
    "    content=f.readlines()\n",
    "    print(f'Content of %s:\\n %s' %(name,content))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
